{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a16801b",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "\n",
    "Some Todos:\n",
    "- `kernel_receivals`\n",
    "    - \n",
    "- `kernel_purchase_orders`\n",
    "    - Consider modified_date_time in purchase_orders: While this can be noisy, the time difference `(modified_date_time - created_date_time)` could be engineered into a feature like `order_revision_duration`.\n",
    "- `extended_materials`\n",
    "    - There are a good deal of entries where `stock_location` is prefixed with DELETED followed by a date. It would be useful to check if there are differences in deliveries before and after that date. My hypothesis is that after it is deleted, there are no more deliveries for that rm_id. If this is a case, a boolean feature `is_deleted` would be powerful.\n",
    "- `extended_transportation`\n",
    "    - packaging_ratio = (gross_weight - net_weight) / gross_weight\n",
    "    Perhaps heavier materials (rm_id A) require more robust (and heavier) packaging than lighter ones (rm_id B).\n",
    "    - weight_discrepancy = (gross_weight - tare_weight) - net_weight.\n",
    "    An average of this discrepancy per supplier_id or transporter_name could be a fantastic feature. It essentially measures the reliability of that supplier's or transporter's data. A model can learn that predictions for transporters with historically high discrepancies are less certain.\n",
    "    - Do not include gross_weight or tare_weight directly in your model's feature set. Instead, use them to engineer these new, more abstract features (packaging_ratio, weight_discrepancy, etc.). Then, you can calculate historical averages of these new features on a per-rm_id, per-supplier_id, or per-transporter_name basis to use in your final model. This avoids data leakage while extracting the valuable information they contain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46cf9390",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "This notebook is meant for all feature engineering. Feel free to add or change sections."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7709fa9e",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befd3fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793599f3",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266605f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename, folder=\"1_raw\"):\n",
    "    \"\"\"\n",
    "    Load data from a CSV file in a subfolder of the project's 'data' directory.\n",
    "    This version is adjusted to work even if the notebook is run from a subfolder.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    filename : str\n",
    "        The name of the file to load, including the extension (e.g., \"data.csv\").\n",
    "    folder : str, optional\n",
    "        The subfolder within 'data' to load from. Defaults to \"1_raw\".\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Go up one level from the current working directory to find the project root\n",
    "        PROJECT_ROOT = Path.cwd().parent\n",
    "\n",
    "        file_path = PROJECT_ROOT / \"data\" / folder / filename\n",
    "\n",
    "        df = pd.read_csv(file_path, sep=\",\")\n",
    "\n",
    "        print(f\"Data loaded successfully from {file_path}\")\n",
    "        return df\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file was not found at {file_path}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while loading the file: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def save_data(df, filename, folder=\"2_interim\"):\n",
    "    \"\"\"\n",
    "    Save a dataframe to a CSV file in a subfolder of the project's 'data' directory.\n",
    "\n",
    "    This function automatically creates the destination folder if it doesn't exist.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        The dataframe to save.\n",
    "    filename : str\n",
    "        The name for the output file, including the extension (e.g., \"processed_orders.csv\").\n",
    "    folder : str, optional\n",
    "        The subfolder within 'data' to save to. Defaults to \"2_interim\".\n",
    "    \"\"\"\n",
    "    try:\n",
    "        PROJECT_ROOT = Path.cwd().parent\n",
    "        save_dir = PROJECT_ROOT / \"data\" / folder\n",
    "        save_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # The full filename, including extension, is now expected\n",
    "        file_path = save_dir / filename\n",
    "\n",
    "        df.to_csv(file_path, sep=\",\", index=False)\n",
    "\n",
    "        print(f\"Data saved successfully to {file_path} âœ…\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while saving the file: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd8d9c0",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab45f7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4201110f",
   "metadata": {},
   "source": [
    "## Introductory Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262da579",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1ae54361",
   "metadata": {},
   "source": [
    "## Saving the Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35b82b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train =\n",
    "# x_train =\n",
    "# y_test = # It may be that we generate K-fold windowed cross-validation datasets on-the-go as we train the model. If so, y_test is not saved here.\n",
    "# x_test =\n",
    "\n",
    "# save_data(x_train, \"x_train\", folder=\"processed\")\n",
    "# save_data(x_test, \"x_test\", folder=\"processed\")\n",
    "# save_data(y_train, \"y_train\", folder=\"processed\")\n",
    "# save_data(y_test, \"y_test\", folder=\"processed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tdt4173-course-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
